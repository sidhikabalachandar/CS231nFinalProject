{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# from chamferdist import ChamferDistance\n",
    "\n",
    "import open3d as o3d\n",
    "\n",
    "import numpy as np \n",
    "from AE import AE\n",
    "from PointCloudDataset import PointCloudDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train = \"data/shape_net_core_uniform_samples_2048/train.txt\"\n",
    "path_to_val   = \"data/shape_net_core_uniform_samples_2048/val.txt\"\n",
    "path_to_test  = \"data/shape_net_core_uniform_samples_2048/test.txt\"\n",
    "path_to_tiny  = \"data/shape_net_core_uniform_samples_2048/tiny.txt\"\n",
    "path_to_tram  = \"data/shape_net_core_uniform_samples_2048/tram.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Train, Val, Test Data\n",
    "\n",
    "trainset = PointCloudDataset(path_to_data = path_to_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "valset = PointCloudDataset(path_to_data = path_to_val)\n",
    "valloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = PointCloudDataset(path_to_data = path_to_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "tinyset = PointCloudDataset(path_to_data = path_to_tiny)\n",
    "tinyloader = torch.utils.data.DataLoader(tinyset, batch_size=5, shuffle=True, num_workers=2)\n",
    "\n",
    "tramset = PointCloudDataset(path_to_data = path_to_tram)\n",
    "tramloader = torch.utils.data.DataLoader(tramset, batch_size=5, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 128\n",
    "epochs = 100\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5683"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tinyset.data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.46253878,  0.00937872, -0.03691137, ..., -0.35992891,\n",
       "         0.00440433,  0.0369372 ]),\n",
       " 'data/shape_net_core_uniform_samples_2048/04468005/40fcd2ccc96b3fbd041917556492646.ply')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tinyset[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# create a model from `AE` autoencoder class\n",
    "# load it to the specified device, either gpu or cpu\n",
    "# model = AE(input_shape=6144).to(device)\n",
    "\n",
    "# create an optimizer object\n",
    "# Adam optimizer with learning rate 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# mean-squared error loss\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = custom_loss\n",
    "# criterion = ChamferDistance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "\n",
    "    nn.Linear(6144, out_features=2048),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.BatchNorm1d(2048),\n",
    "    \n",
    "    nn.Linear(2048, out_features=1024),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    \n",
    "    nn.Linear(1024, out_features=128),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.BatchNorm1d(128),\n",
    "    \n",
    "    nn.Linear(128, out_features=128),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.BatchNorm1d(128),\n",
    "    \n",
    "    nn.Linear(128, out_features=128),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.BatchNorm1d(128),\n",
    "   \n",
    "    nn.Linear(128, out_features=1024),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    \n",
    "    nn.Linear(1024, out_features=2048),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.BatchNorm1d(2048),\n",
    "    \n",
    "    nn.Linear(2048, out_features=6144),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/100, recon loss = 0.00116359\n",
      "epoch : 2/100, recon loss = 0.00112142\n",
      "epoch : 3/100, recon loss = 0.00098377\n",
      "epoch : 4/100, recon loss = 0.00086382\n",
      "epoch : 5/100, recon loss = 0.00068520\n",
      "epoch : 6/100, recon loss = 0.00055723\n",
      "epoch : 7/100, recon loss = 0.00041335\n",
      "epoch : 8/100, recon loss = 0.00034347\n",
      "epoch : 9/100, recon loss = 0.00030372\n",
      "epoch : 10/100, recon loss = 0.00025549\n",
      "epoch : 11/100, recon loss = 0.00022266\n",
      "epoch : 12/100, recon loss = 0.00020443\n",
      "epoch : 13/100, recon loss = 0.00018425\n",
      "epoch : 14/100, recon loss = 0.00016138\n",
      "epoch : 15/100, recon loss = 0.00014307\n",
      "epoch : 16/100, recon loss = 0.00013061\n",
      "epoch : 17/100, recon loss = 0.00012063\n",
      "epoch : 18/100, recon loss = 0.00011031\n",
      "epoch : 19/100, recon loss = 0.00009948\n",
      "epoch : 20/100, recon loss = 0.00008952\n",
      "epoch : 21/100, recon loss = 0.00008126\n",
      "epoch : 22/100, recon loss = 0.00007467\n",
      "epoch : 23/100, recon loss = 0.00006917\n",
      "epoch : 24/100, recon loss = 0.00006362\n",
      "epoch : 25/100, recon loss = 0.00005759\n",
      "epoch : 26/100, recon loss = 0.00005203\n",
      "epoch : 27/100, recon loss = 0.00004767\n",
      "epoch : 28/100, recon loss = 0.00004414\n",
      "epoch : 29/100, recon loss = 0.00004077\n",
      "epoch : 30/100, recon loss = 0.00003726\n",
      "epoch : 31/100, recon loss = 0.00003385\n",
      "epoch : 32/100, recon loss = 0.00003089\n",
      "epoch : 33/100, recon loss = 0.00002837\n",
      "epoch : 34/100, recon loss = 0.00002608\n",
      "epoch : 35/100, recon loss = 0.00002389\n",
      "epoch : 36/100, recon loss = 0.00002181\n",
      "epoch : 37/100, recon loss = 0.00001982\n",
      "epoch : 38/100, recon loss = 0.00001799\n",
      "epoch : 39/100, recon loss = 0.00001641\n",
      "epoch : 40/100, recon loss = 0.00001501\n",
      "epoch : 41/100, recon loss = 0.00001360\n",
      "epoch : 42/100, recon loss = 0.00001219\n",
      "epoch : 43/100, recon loss = 0.00001096\n",
      "epoch : 44/100, recon loss = 0.00000995\n",
      "epoch : 45/100, recon loss = 0.00000898\n",
      "epoch : 46/100, recon loss = 0.00000798\n",
      "epoch : 47/100, recon loss = 0.00000709\n",
      "epoch : 48/100, recon loss = 0.00000633\n",
      "epoch : 49/100, recon loss = 0.00000562\n",
      "epoch : 50/100, recon loss = 0.00000498\n",
      "epoch : 51/100, recon loss = 0.00000442\n",
      "epoch : 52/100, recon loss = 0.00000392\n",
      "epoch : 53/100, recon loss = 0.00000344\n",
      "epoch : 54/100, recon loss = 0.00000300\n",
      "epoch : 55/100, recon loss = 0.00000266\n",
      "epoch : 56/100, recon loss = 0.00000239\n",
      "epoch : 57/100, recon loss = 0.00000214\n",
      "epoch : 58/100, recon loss = 0.00000188\n",
      "epoch : 59/100, recon loss = 0.00000167\n",
      "epoch : 60/100, recon loss = 0.00000151\n",
      "epoch : 61/100, recon loss = 0.00000138\n",
      "epoch : 62/100, recon loss = 0.00000126\n",
      "epoch : 63/100, recon loss = 0.00000115\n",
      "epoch : 64/100, recon loss = 0.00000105\n",
      "epoch : 65/100, recon loss = 0.00000096\n",
      "epoch : 66/100, recon loss = 0.00000088\n",
      "epoch : 67/100, recon loss = 0.00000082\n",
      "epoch : 68/100, recon loss = 0.00000076\n",
      "epoch : 69/100, recon loss = 0.00000069\n",
      "epoch : 70/100, recon loss = 0.00000062\n",
      "epoch : 71/100, recon loss = 0.00000057\n",
      "epoch : 72/100, recon loss = 0.00000052\n",
      "epoch : 73/100, recon loss = 0.00000048\n",
      "epoch : 74/100, recon loss = 0.00000043\n",
      "epoch : 75/100, recon loss = 0.00000038\n",
      "epoch : 76/100, recon loss = 0.00000034\n",
      "epoch : 77/100, recon loss = 0.00000031\n",
      "epoch : 78/100, recon loss = 0.00000028\n",
      "epoch : 79/100, recon loss = 0.00000025\n",
      "epoch : 80/100, recon loss = 0.00000022\n",
      "epoch : 81/100, recon loss = 0.00000020\n",
      "epoch : 82/100, recon loss = 0.00000018\n",
      "epoch : 83/100, recon loss = 0.00000016\n",
      "epoch : 84/100, recon loss = 0.00000014\n",
      "epoch : 85/100, recon loss = 0.00000013\n",
      "epoch : 86/100, recon loss = 0.00000012\n",
      "epoch : 87/100, recon loss = 0.00000011\n",
      "epoch : 88/100, recon loss = 0.00000010\n",
      "epoch : 89/100, recon loss = 0.00000009\n",
      "epoch : 90/100, recon loss = 0.00000008\n",
      "epoch : 91/100, recon loss = 0.00000007\n",
      "epoch : 92/100, recon loss = 0.00000007\n",
      "epoch : 93/100, recon loss = 0.00000006\n",
      "epoch : 94/100, recon loss = 0.00000005\n",
      "epoch : 95/100, recon loss = 0.00000005\n",
      "epoch : 96/100, recon loss = 0.00000005\n",
      "epoch : 97/100, recon loss = 0.00000004\n",
      "epoch : 98/100, recon loss = 0.00000004\n",
      "epoch : 99/100, recon loss = 0.00000003\n",
      "epoch : 100/100, recon loss = 0.00000003\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    loss = 0\n",
    "    for index, (batch_features, _) in enumerate(tinyloader):\n",
    "        # reshape mini-batch data to [N, 784] matrix\n",
    "        # load it to the active device\n",
    "\n",
    "        batch_features = batch_features.to(device).float()\n",
    "\n",
    "        # reset the gradients back to zero\n",
    "        # PyTorch accumulates gradients on subsequent backward passes\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute reconstructions\n",
    "        outputs = model(batch_features).to(device).float()\n",
    "\n",
    "        # compute training reconstruction loss\n",
    "        train_loss = criterion(outputs, batch_features)\n",
    "\n",
    "        # compute accumulated gradients\n",
    "        train_loss.backward()\n",
    "\n",
    "        # perform parameter update based on current gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # add the mini-batch training loss to epoch loss\n",
    "        loss += train_loss.item()\n",
    "\n",
    "    # compute the epoch training loss\n",
    "    loss = loss / len(trainloader)\n",
    "\n",
    "    # display the epoch training loss\n",
    "    print(\"epoch : {}/{}, recon loss = {:.8f}\".format(epoch + 1, epochs, loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_path:data/shape_net_core_uniform_samples_2048/04468005/19daec6f2602f9c0dc14ba0818ee5cec.ply\n"
     ]
    }
   ],
   "source": [
    "#for predictions\n",
    "name = \"tram_test\"\n",
    "import shutil\n",
    "\n",
    "for single_test_feature, single_test_path in tramloader:\n",
    "    input_tensor = single_test_feature.float()         #(128, 6144)\n",
    "    \n",
    "    print(\"input_path:{}\".format(single_test_path[0]))\n",
    "    \n",
    "    output_tensor = model(input_tensor)                #(128, 6144,)\n",
    "    reshape_tensor = output_tensor[0].reshape(2048, 3) #(2048, 3)\n",
    "    #print(output_tensor)\n",
    "    \n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(reshape_tensor.detach().cpu().numpy())\n",
    "    o3d.io.write_point_cloud(\"/Users/oswald/Documents/MATLAB/CS231N/{}_predict_ae.ply\".format(name), pcd)\n",
    "    shutil.copyfile(single_test_path[0], \"/Users/oswald/Documents/MATLAB/CS231N/{}_original_ae.ply\".format(name))\n",
    "    \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6144])\n",
      "input_path:('data/shape_net_core_uniform_samples_2048/02871439/20e2da108eb42b52c16a7f7cb5642902.ply',)\n",
      "torch.Size([2048, 3])\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "for single_test_feature, single_test_path in trainloader:\n",
    "    input_tensor = single_test_feature.float()         #(6144,)\n",
    "    \n",
    "    print(single_test_feature.size())\n",
    "    \n",
    "    print(\"input_path:{}\".format(single_test_path))\n",
    "    \n",
    "#     output_tensor = model(input_tensor)                #(6144,)\n",
    "    reshape_tensor = input_tensor.reshape(2048, 3)    #(2048, 3)\n",
    "    print(reshape_tensor.size())\n",
    "    #print(output_tensor)\n",
    "    \n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(reshape_tensor.detach().cpu().numpy())\n",
    "    o3d.io.write_point_cloud(\"./reshaped_input_ae.ply\", pcd)\n",
    "    shutil.copyfile(single_test_path[0], \"./original_input_ae.ply\")\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (model.encoder_hidden_layer.weight * 10**9\n",
    "b = model.encoder_output_layer.weight * 10**9\n",
    "c = model.decoder_hidden_layer.weight * 10**9\n",
    "d = model.decoder_output_layer.weight * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
